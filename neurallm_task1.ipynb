{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5313d72c-9835-45fb-bfcb-90cf977062b6",
   "metadata": {},
   "source": [
    "Homework 4: Neural Language Models (& ðŸŽƒ SpOoKy ðŸ‘» authors ðŸ§Ÿ data)\n",
    "----\n",
    "\n",
    "Due date: March 13th, 2025 @ 9pm Boston time\n",
    "\n",
    "Points: (will be listed on Canvas)\n",
    "\n",
    "Goals:\n",
    "- explore & use word embeddings\n",
    "- train neural models from the ground up!\n",
    "- get comfy with a modern neural net library (`pytorch`)\n",
    "    - you'll likelye make close friends with the docs: https://pytorch.org/tutorials/beginner/basics/intro.html \n",
    "- evaluate neural vs. vanilla n-gram language models\n",
    "\n",
    "Complete in groups of: __two (pairs)__. If you prefer to work on your own, you may, but be aware that this homework has been designed as a partner project!\n",
    "\n",
    "Allowed python modules:\n",
    "- `gensim`, `numpy`, `matplotlib`, `pytorch`, `nltk`, `pandas`, `sci-kit learn` (`sklearn`), `seaborn`, all built-in python libraries (e.g. `math` and `string`), and anything else we imported in the starter code\n",
    "- if you would like to use a library not on this list, post on piazza to request permission\n",
    "- all *necessary* imports have been included for you (all imports that we used in our solution)\n",
    "\n",
    "Instructions:\n",
    "- Complete outlined problems in this notebook. \n",
    "- When you have finished, __clear the kernel__ and __run__ your notebook \"fresh\" from top to bottom. Ensure that there are __no errors__. \n",
    "    - If a problem asks for you to write code that does result in an error (as in, the answer to the problem is an error), leave the code in your notebook but commented out so that running from top to bottom does not result in any errors.\n",
    "- Double check that you have completed Task 0.\n",
    "- Submit your work on Gradescope.\n",
    "- Double check that your submission on Gradescope looks like you believe it should __and__ that all partners are included (for partner work).\n",
    "\n",
    "Data processing:\n",
    "- You may __choose__ how you would like to tokenize your text for this assignment\n",
    "- You'll want to __deal with internal commas (commas inside of the sentences) appropriately__ when you read in the data, so use the python [`csv` module](https://docs.python.org/3/library/csv.html) or some other module to read the csv in (vs. splitting on commas).\n",
    "\n",
    "Warnings:\n",
    "- You might see:\n",
    "```\n",
    "notebook controller is DISPOSED. \n",
    "View Jupyter log for further details.\n",
    "```\n",
    "This is not an error per se--go to the last cell that ran successfully (or the first cell) and run them one-by-one, waiting for the prior one to finish running before moving to the next.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5940a9b-f44d-49df-b0da-0170ffc6b41d",
   "metadata": {},
   "source": [
    "Names\n",
    "----\n",
    "Names: __YOUR NAMES HERE__ (Write these in every notebook you submit.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7228d8-3ab8-4038-9f49-c4e58938fde5",
   "metadata": {},
   "source": [
    "Task 1: Provided Data Write-Up (7 points)\n",
    "---\n",
    "\n",
    "Every time you use a data set in an NLP application (or in any software application), you should be able to answer a set of questions about that data. Answer these now. Default to no more than 1 sentence per question needed. If more explanation is necessary, do give it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381e3e2a-4db8-4554-a487-267358be5a6f",
   "metadata": {},
   "source": [
    "This is about the __provided__ ðŸŽƒ spooky ðŸ‘» authors ðŸ§Ÿ data set. Please __bold__ your answers to all written questions! Each row in this dataset represents one sentence.\n",
    "\n",
    "1. Where did you get the data from? The provided dataset is the training data from: https://www.kaggle.com/competitions/spooky-author-identification \n",
    "2. (1 pt) How was the data collected (where did the people acquiring the data get it from and how)?\n",
    "3. (1 pt) What is your data? (i.e. newswire, tweets, books, blogs, etc)\n",
    "4. (1 pt) Who produced the data? (who were the authors of the text? Your answer might be a specific person or a particular group of people)\n",
    "5. (1 pt) How large is the dataset? (# texts/sentences, # total tokens by word)\n",
    "6. (1 pt) What are the minimum, maximum, and average sentence lengths (by tokens) in your dataset?\n",
    "7. (2 pts) How large is the vocabulary, both tokenized by character and by word?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc22bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import your libraries here\n",
    "\n",
    "# Remember to restart your kernel if you change the contents of this file!\n",
    "import neurallm_utils as nutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30f774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code that you need to answer the above questions here!\n",
    "# but make sure that you leave the answers you want us to grade in the markdown!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9e2e20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
