{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5Yox0gG1DsF"
   },
   "source": [
    "Homework 4: Neural Language Models  (& ðŸŽƒ SpOoKy ðŸ‘» authors ðŸ§Ÿ data) - Task 4, Option B\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Names\n",
    "----\n",
    "Names: __Katherine aristizabal, Jose Meza Llamosas__ (Write these in every notebook you submit.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4: Compare your generated sentences (25 points)\n",
    "----\n",
    "\n",
    "In this task, you'll analyze one of the models that you produced in Task 3. You'll need to compare against the corresponding file that was generated from the vanilla n-gram language model.\n",
    "\n",
    "Choose *__one__* of option A or B (this notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "316H0xSh1DsQ"
   },
   "source": [
    "Option B: Evaluate the generated sentences of *word*-based models\n",
    "----\n",
    "\n",
    "Your job for this option is to measure the quality of your generated sentences for word-based models. For this option you *must* survey at least 3 people who are __not__ in this course. They need to speak and read the language that you are evaluating, but they need not be native speakers.\n",
    "\n",
    "You will evaluate the quality of the generated sentences in the following way:\n",
    "- Generate 20 sentences from your best word-based neural model. (Value of hyperparameters and n value up to you).\n",
    "- Using the same level of n-gram, pair these sentences with provided sentences from the vanilla n-gram model. If you want to evaluate a model with N != 3, 4, or 5, then you'll need to train your vanilla n-gram model and generate your own comparison sentences. Ignore sentences with \\<UNK\\> in them for even comparison, so you'll need to over-generate to get 20.\n",
    "    - Pair them (roughly) based on sentence length, so that each pair has sentences that are a roughly similar number of tokens.\n",
    "\n",
    "Next, build a survey. For each pair of (neural LM sentence, vanilla n-ngram LM sentence), you'll ask the survey taker three binary selection questions:\n",
    "1. which sentence is more grammatical?\n",
    "2. which sentence makes more sense, semantically (in meaning)?\n",
    "3. Overall, which sentence do you prefer?\n",
    "\n",
    "\n",
    "Finally, you'll evaluate your survey results __programmatically__ (export them as a csv). Calculate the following:\n",
    "1. What percentage of neural vs. vanilla n-gram LM sentences were preferred, separated along each of the three dimensions?\n",
    "2. What is [Krippendorff's alpha](https://en.wikipedia.org/wiki/Krippendorff%27s_alpha) for your survey data? \n",
    "\n",
    "You are welcome to use a pre-built python implmenetation of the Krippendorff's alpha calculation, such as [this one](https://pypi.org/project/krippendorff/). Krippendorff's alpha is one way to measure interannotator agreement â€” the extent to which your survey respondants agree with one another.\n",
    "\n",
    "You will submit your survey data (as a csv called `survey_results.csv`) __and__ your paired sentences (`paired.txt`, formatted in a way that is easy to understand) alongside this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " #!pip install krippendorff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yc/qn_vgcrn7bl10040kgrlhnvh0000gn/T/ipykernel_18501/3465176895.py:9: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n",
      "[nltk_data] Downloading package punkt to /Users/0wner/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /Users/0wner/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# your imports here\n",
    "\n",
    "import krippendorff\n",
    " \n",
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "# if you want fancy progress bars\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "# Remember to restart your kernel if you change the contents of this file!\n",
    "import task4_utils as nutils\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "# This function gives us nice print-outs of our models.\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is really austrian sale facilis maouth recalling peering combattendo conspicuously aims madhouse.\n",
      "This is really indubitably careful superinduced collated aoutside intrusive cyclops themes continuance hack.\n",
      "This is really contemplations theoretical matutinal exhumation bookseller labels overlooks white servile sowing.\n",
      "This is really traits determined ritual deepened motionless obstacle rÃ¨duit hooper masterminds cum.\n",
      "This is really tales boccaccio disintegrated marquis illyrian subserved droughts line crawled loading.\n",
      "This is really pulse attains heerd paid gregory impart ellent recusant interiorly incubus.\n",
      "This is really chaldaea buzrael experts wharves thickly divulge journalists palsied extremities logically.\n",
      "This is really achievements tremors purifying phipps intemperate kettles groans courtesied proceeds grope.\n",
      "This is really transported donned pleases petitions gentry moods write songfully bones nest.\n",
      "This is really boldest shewn resourses rufus songs frxg lend pauline altitude gallant.\n",
      "This is really bye arrows vibrations caude arc abernethy ettrick blossoming ensconced took.\n",
      "This is really acquaintances barometers guinea sable disgust arranged ceiling bracelet clotted inane.\n",
      "This is really daedalus kindliness quarrels jointly improbable fountains shallows compensate naples killer.\n",
      "This is really robust eyelashes archimedean steen pleiades thankfully law larnt throttling pearl.\n",
      "This is really vesture attire immortality trickle immoveable pots hunters royalists remaining bellowing.\n",
      "This is really overhear hxg abatement system maledictions evadne acorns privileges boatswain logged.\n",
      "This is really tottering scenic mown bush ostensibly faintings horizontal unsheathing northeast papers.\n",
      "This is really puffy dishonoured interested dazedness farce learnt flout nez thus prentice.\n",
      "This is really dimly swirling chicago pear spectrally june ferny riot postponement mockingly.\n",
      "This is really ebenezer autres roule lichen footsteps tucked investigating baldly monotonously ungreeted.\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "EMBEDDINGS_SIZE = 50\n",
    "NGRAM = 3\n",
    "NUM_SEQUENCES_PER_BATCH = 128\n",
    "\n",
    "TRAIN_FILE = 'spooky_author_train.csv' # The file to train your language model on\n",
    "OUTPUT_WORDS = 'generated_wordbased.txt' # The file to save your generated sentences for word-based LM\n",
    "OUTPUT_CHARS = 'generated_charbased.txt' # The file to save your generated sentences for char-based LM\n",
    "\n",
    "# you can update these file names if you want to depending on how you are exploring \n",
    "# hyperparameters\n",
    "EMBEDDING_SAVE_FILE_WORD = f\"spooky_embedding_word_{EMBEDDINGS_SIZE}.model\" # The file to save your word embeddings to\n",
    "EMBEDDING_SAVE_FILE_CHAR = f\"spooky_embedding_char_{EMBEDDINGS_SIZE}.model\" # The file to save your char embeddings to\n",
    "MODEL_FILE_WORD = f'spooky_author_model_word_{NGRAM}.pt' # The file to save your trained word-based neural LM to\n",
    "MODEL_FILE_CHAR = f'spooky_author_model_char_{NGRAM}.pt' # The file to save your trained char-based neural LM to\n",
    "\n",
    "FINAL_OUTPUT_WORDS = \"final_word_generated.txt\"\n",
    "\n",
    "\n",
    "import zipfile\n",
    "import pickle\n",
    "\n",
    "\n",
    "#load previously generated sentences\n",
    "#f = open(OUTPUT_WORDS, \"r\", encoding=\"utf-8\", errors=\"ignore\")\n",
    "#contents = f.readlines()\n",
    "with zipfile.ZipFile(FINAL_OUTPUT_WORDS, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"extracted_folder\")\n",
    "\n",
    "with open(\"extracted_folder/final_word_generated/data.pkl\", \"rb\") as f:\n",
    "    contents =  pickle.load(f)\n",
    "#task3_list = nutils.read_file_spooky(OUTPUT_WORDS, ngram=NGRAM, char=False)\n",
    "#chosen_sentences = contents[:20]\n",
    "lines = contents.split('\\n')\n",
    "for line in lines[:20]:\n",
    "    print(line)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pair 0\n",
      "This is really boldest shewn resourses rufus songs frxg lend pauline altitude gallant.\n",
      "why the third degree ?\n",
      "pair 1\n",
      "This is really pulse attains heerd paid gregory impart ellent recusant interiorly incubus.\n",
      "nor did this seem extravagant .\n",
      "pair 2\n",
      "This is really bye arrows vibrations caude arc abernethy ettrick blossoming ensconced took.\n",
      "i began to murmur , to hesitate , to resist .\n",
      "pair 3\n",
      "This is really puffy dishonoured interested dazedness farce learnt flout nez thus prentice.\n",
      "never a competent navigator , i could only wait .\n",
      "pair 4\n",
      "This is really transported donned pleases petitions gentry moods write songfully bones nest.\n",
      "alas we had fallen upon the most evil of all our evil days .\n",
      "pair 5\n",
      "This is really dimly swirling chicago pear spectrally june ferny riot postponement mockingly.\n",
      "answer me , i conjure you , with confidence and sincerity . ''\n",
      "pair 6\n",
      "This is really robust eyelashes archimedean steen pleiades thankfully law larnt throttling pearl.\n",
      "so on the night of july , , and remained with us until late in the night .\n",
      "pair 7\n",
      "This is really traits determined ritual deepened motionless obstacle rÃ¨duit hooper masterminds cum.\n",
      "one of very remarkable character , and i had selected his features as beautiful .\n",
      "pair 8\n",
      "This is really overhear hxg abatement system maledictions evadne acorns privileges boatswain logged.\n",
      "we had many foreign friends whom we eagerly sought out , and relieved from dreadful penury .\n",
      "pair 9\n",
      "This is really acquaintances barometers guinea sable disgust arranged ceiling bracelet clotted inane.\n",
      "at first i wished to hurry on , although drenched by the rain which poured from a black and comfortless sky .\n",
      "pair 10\n",
      "This is really austrian sale facilis maouth recalling peering combattendo conspicuously aims madhouse.\n",
      "had my uncle referred to these cases by name instead of merely by number , i should have sunk under my hardships .\n",
      "pair 11\n",
      "This is really tales boccaccio disintegrated marquis illyrian subserved droughts line crawled loading.\n",
      "yet all these appearances have been given i beg pardon will be given by the learned of future ages , to the ashimah of the syrians .\n",
      "pair 12\n",
      "This is really tottering scenic mown bush ostensibly faintings horizontal unsheathing northeast papers.\n",
      "she had no experience beyond her father 's cottage ; and the mansion of the lord of the manor was the chiefest type of grandeur she could conceive .\n",
      "pair 13\n",
      "This is really vesture attire immortality trickle immoveable pots hunters royalists remaining bellowing.\n",
      "he supposes that , had this been the case , we know our duty better than to bring him into the presence of the third personage who stood at her elbow .\n",
      "pair 14\n",
      "This is really ebenezer autres roule lichen footsteps tucked investigating baldly monotonously ungreeted.\n",
      "the floors are of square tiles , the chairs and tables of black looking wood with thin crooked legs and puppy feet like the tables , is seated the old man of the house himself .\n",
      "pair 15\n",
      "This is really chaldaea buzrael experts wharves thickly divulge journalists palsied extremities logically.\n",
      "i resolved , therefore , that if my immediate union with my cousin would conduce either to hers or my father 's happiness , my adversary 's designs against my life should not retard it a single hour .\n",
      "pair 16\n",
      "This is really achievements tremors purifying phipps intemperate kettles groans courtesied proceeds grope.\n",
      "`` but how was i terrified when i viewed myself in a transparent pool at first i started back , unable to believe that it formed part of some exotic pirate hoard discovered by old captain obed marsh .\n",
      "pair 17\n",
      "This is really daedalus kindliness quarrels jointly improbable fountains shallows compensate naples killer.\n",
      "surely , man had never before so terribly altered , in so brief a period , as had roderick usher it was with difficulty that i could bring myself to admit the identity of the corpse with the marie rogÃªt who is missing .\n",
      "pair 18\n",
      "This is really indubitably careful superinduced collated aoutside intrusive cyclops themes continuance hack.\n",
      "she pictured to herself the anguish of his solitude ; she remembered with what eager delight he had in former days made her the partner of his joyful hopes with what grateful affection he received her sympathy in his cares .\n",
      "pair 19\n",
      "This is really contemplations theoretical matutinal exhumation bookseller labels overlooks white servile sowing.\n",
      "several extensive perforations existed ; and , at the various newspaper offices , a copy of every paper in which , from first to last , had been published any decisive information in regard to this sad affair is , and was from the first , through the blue chamber to the purple through the purple to the green through the green to the orange through this again to the white and even thence to the violet , ere a decided movement had been made to arrest him .\n"
     ]
    }
   ],
   "source": [
    "VANILLA_FILE = 'spooky_vanilla_5_word.txt' # The evaluation file of words\n",
    "\n",
    "#sort generated sentence by sentence length\n",
    "sorted_words = sorted(lines[:20], key=len)\n",
    "\n",
    "#divide generated sentences into ngrams\n",
    "ngram_sentences = []\n",
    "for line in sorted_words:\n",
    "    ngram_sentences.append(nutils.create_ngrams(line, n=NGRAM))\n",
    "#print(ngram_sentences)\n",
    "\n",
    "with open(VANILLA_FILE, \"r\") as f:\n",
    "    contents_v =  f.read()\n",
    "\n",
    "lines_v = contents_v.split('\\n')\n",
    "\n",
    "#sort them by sentence length\n",
    "sorted_words_v = sorted(lines_v[:20], key=len)\n",
    "#print(\"sorted\" , nutils.format_sentence(sorted_words_v))\n",
    "\n",
    "#divide vanilla text into ngrams\n",
    "vanilla_ngrams = []\n",
    "\n",
    "for line in sorted_words_v:\n",
    "    #print(line)\n",
    "    vanilla_ngrams.append(nutils.create_ngrams(line, n=NGRAM))\n",
    "#print(vanilla_ngrams)\n",
    "\n",
    "for i in range(len(sorted_words)):\n",
    "    print(\"pair\", i)\n",
    "    print(sorted_words[i])\n",
    "    print(sorted_words_v[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that your reported results are nicely formatted!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "wordembeddings_solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05041e657fa0436a83611a3d2d345b99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3cd0685004814c0d974a1d809e0e2b4f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b0dca775977048f38841afae3d906eb6",
      "value": "100%"
     }
    },
    "140057e9712f46af9ebf5825ef9b1390": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_05041e657fa0436a83611a3d2d345b99",
       "IPY_MODEL_a818afa6bb4f43c8b7e32a3c04f17211",
       "IPY_MODEL_72a47718e310461fbd61b312f7bf7cfe"
      ],
      "layout": "IPY_MODEL_488b55855d4d4ffc8af6d3d77aa3fdf8"
     }
    },
    "150adc7de7f54d63a215482e6a977067": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1b93060412f54083b6dd7b9203ae55d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3cd0685004814c0d974a1d809e0e2b4f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "488b55855d4d4ffc8af6d3d77aa3fdf8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72a47718e310461fbd61b312f7bf7cfe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a4d9e5b3a1e144e6b34a55ab5cbce43f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_150adc7de7f54d63a215482e6a977067",
      "value": " 19579/19579 [00:00&lt;00:00, 18295.70it/s]"
     }
    },
    "843343b9adc84d949f839d51814d55aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a4d9e5b3a1e144e6b34a55ab5cbce43f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a818afa6bb4f43c8b7e32a3c04f17211": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b93060412f54083b6dd7b9203ae55d0",
      "max": 19579,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_843343b9adc84d949f839d51814d55aa",
      "value": 19579
     }
    },
    "b0dca775977048f38841afae3d906eb6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
